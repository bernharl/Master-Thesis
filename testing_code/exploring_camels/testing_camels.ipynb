{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    name_getter = lambda x: x != 3\n",
    "    names = pd.read_table(\n",
    "        \"basin_dataset_public_v1p2/basin_mean_forcing/daymet/01/01013500_lump_cida_forcing_leap.txt\",\n",
    "        skiprows=name_getter,\n",
    "        sep=\" \",\n",
    "    ).columns.to_numpy()\n",
    "    header = np.zeros(len(names) - 3, dtype=object)\n",
    "    header[0] = \"Time\"\n",
    "    header[1:] = names[4:]\n",
    "    del names\n",
    "    df = pd.read_table(\n",
    "        \"basin_dataset_public_v1p2/basin_mean_forcing/daymet/01/01013500_lump_cida_forcing_leap.txt\",\n",
    "        names=header,\n",
    "        skiprows=4,\n",
    "    )\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "    df[\"Time\"] = (df[\"Time\"] - df[\"Time\"][0]).dt.days\n",
    "    streamflow = pd.read_table(\n",
    "        \"basin_dataset_public_v1p2/usgs_streamflow/01/01013500_streamflow_qc.txt\",\n",
    "        header=None,\n",
    "        sep=\"\\s+\",\n",
    "    ).astype(\"str\")\n",
    "    del streamflow[0]\n",
    "    for i in range(len(streamflow[1])):\n",
    "        streamflow[1][i] += \" \" + streamflow[2][i] + \" \" + streamflow[3][i]\n",
    "    streamflow[1] = pd.to_datetime(streamflow[1])\n",
    "    del streamflow[2]\n",
    "    del streamflow[3]\n",
    "    streamflow[1] = (streamflow[1] - streamflow[1][0]).dt.days\n",
    "    df = df[streamflow[5] != \"M\"]\n",
    "    streamflow = streamflow[streamflow[5] != \"M\"]\n",
    "    del streamflow[5]\n",
    "    streamflow.columns = [\"Time\", \"Flow\"]\n",
    "    return df, streamflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self, load_data, device):\n",
    "        df, streamflow = load_data()\n",
    "        dayl = (\n",
    "            torch.from_numpy(df[\"dayl(s)\"].to_numpy()).view(-1, 1).float().to(device)[:]\n",
    "        )\n",
    "        prcp = (\n",
    "            torch.from_numpy(df[\"prcp(mm/day)\"].to_numpy())\n",
    "            .view(-1, 1)\n",
    "            .float()\n",
    "            .to(device)[:]\n",
    "        )\n",
    "        self.y = (\n",
    "            torch.from_numpy(streamflow[\"Flow\"].to_numpy().astype(\"float\"))\n",
    "            .view(-1, 1, 1)\n",
    "            .float()\n",
    "            .to(device)[:]\n",
    "        )\n",
    "\n",
    "        self.x = torch.zeros((len(df[\"Time\"]), 1, 2)).to(device)\n",
    "        self.x[:, :, 0] = dayl[:]\n",
    "        self.x[:, :, 1] = prcp[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nodes=51, layers=1, inputs=2, parallel=True):\n",
    "        super().__init__()\n",
    "        if parallel:\n",
    "            self.device = \"cuda:0\"\n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size=inputs, hidden_size=nodes, num_layers=layers\n",
    "            ).to(self.device)\n",
    "            self.lstm = nn.DataParallel(\n",
    "                self.lstm, device_ids=[\"cuda:0\", \"cuda:1\"], output_device=self.device\n",
    "            )\n",
    "            self.output_layer = nn.Linear(nodes, 1).to(self.device)\n",
    "\n",
    "        else:\n",
    "            self.device = \"cuda:1\"\n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size=inputs, hidden_size=nodes, num_layers=layers\n",
    "            ).to(self.device)\n",
    "\n",
    "            self.output_layer = nn.Linear(nodes, 1).to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, (h_n, c_n) = self.lstm(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, lr, parallel=True, verbose=True):\n",
    "    if parallel:\n",
    "        device = \"cuda:0\"\n",
    "    else:\n",
    "        device = \"cuda:1\"\n",
    "    \"\"\"dayl = torch.from_numpy(df[\"dayl(s)\"].to_numpy()).view(-1, 1).float().to(device)[:]\n",
    "    prcp = (\n",
    "        torch.from_numpy(df[\"prcp(mm/day)\"].to_numpy())\n",
    "        .view(-1, 1)\n",
    "        .float()\n",
    "        .to(device)[:]\n",
    "    )\n",
    "    y = (\n",
    "        torch.from_numpy(streamflow[\"Flow\"].to_numpy().astype(\"float\"))\n",
    "        .view(-1, 1)\n",
    "        .float()\n",
    "        .to(device)[:]\n",
    "    )\n",
    "\n",
    "    x = torch.zeros((len(df[\"Time\"]), 1, 2)).to(device)\n",
    "    x[:, :, 0] = dayl[:]\n",
    "    x[:, :, 1] = prcp[:]\n",
    "    print(x.size())\"\"\"\n",
    "    data = Data(load_data, device)\n",
    "    model = Net(parallel=parallel)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2)\n",
    "    loss_func = nn.MSELoss()\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(data.x)\n",
    "        loss = loss_func(y_pred, data.y)\n",
    "        if verbose:\n",
    "            print(f\"Epoch {i}: {loss.item()}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 5611014.0\n",
      "Epoch 1: 5506238.5\n",
      "Epoch 2: 5403879.0\n",
      "Epoch 3: 5303975.0\n",
      "Epoch 4: 5206563.5\n",
      "Epoch 5: 5111678.0\n",
      "Epoch 6: 5019350.5\n",
      "Epoch 7: 4929607.5\n",
      "Epoch 8: 4842471.5\n",
      "Epoch 9: 4757964.0\n"
     ]
    }
   ],
   "source": [
    "train(10, 1, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12692, 1, 2])\n",
      "Epoch 0: 5611925.5\n",
      "Epoch 1: 5527316.5\n",
      "Epoch 2: 5444274.0\n",
      "Epoch 3: 5362825.5\n",
      "Epoch 4: 5282994.5\n",
      "Epoch 5: 5204805.5\n",
      "Epoch 6: 5128277.0\n",
      "Epoch 7: 5053431.0\n",
      "Epoch 8: 4980284.0\n",
      "Epoch 9: 4908851.5\n"
     ]
    }
   ],
   "source": [
    "train(10, 1, True, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
