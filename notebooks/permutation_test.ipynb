{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Union, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from camelsml.metrics import calc_nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(folder: Union[Path, str], model_type: str, seed: int) -> Dict:\n",
    "    if isinstance(folder, str):\n",
    "        folder = Path(folder)\n",
    "    if not folder.exists():\n",
    "        raise FileNotFoundError(f\"No directory found at {folder}\")\n",
    "    nse_values = defaultdict(dict)\n",
    "    epochs = len(list(folder.rglob(f\"{model_type}_seed{seed}_epoch_*.p\")))\n",
    "    if epochs == 0:\n",
    "        raise FileNotFoundError(f\"No validation runs found\")\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        file = folder / f\"{model_type}_seed{seed}_epoch_{epoch}.p\"\n",
    "        with open(file, \"rb\") as results_file:\n",
    "            results = pickle.load(results_file)\n",
    "        for basin in results.keys():\n",
    "            nse_values[f\"epoch_{epoch}\"][basin] = calc_nse(\n",
    "                obs=results[basin][\"qobs\"].to_numpy(),\n",
    "                sim=results[basin][\"qsim\"].to_numpy(),\n",
    "            )\n",
    "    return nse_values\n",
    "\n",
    "\n",
    "def load_cv_results(\n",
    "    main_folder: Union[Path, str], k, model_type: str, seed: int, epoch: int = 30\n",
    ") -> Dict:\n",
    "    if isinstance(main_folder, str):\n",
    "        main_folder = Path(main_folder)\n",
    "    if not main_folder.exists():\n",
    "        raise FileNotFoundError(f\"No directory found at {main_folder}\")\n",
    "    results = {}\n",
    "    full_results = defaultdict(dict)\n",
    "    for i in tqdm(range(k)):\n",
    "        folder = main_folder / str(i)\n",
    "        folder = list(folder.glob(\"*\"))\n",
    "        if len(folder) != 1:\n",
    "            warnings.warn(f\"Check your file structure in {i}\")\n",
    "        folder = folder[0]\n",
    "        results[i] = load_results(folder, model_type, seed)\n",
    "        for key in list(results[i].keys())[:epoch]:\n",
    "            for basin in results[i][key].keys():\n",
    "                full_results[key][basin] = results[i][key][basin]\n",
    "    return full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(folder: Union[str, Path], k: int = 5) -> Dict:\n",
    "    folder = Path(folder)\n",
    "    results = []\n",
    "    for i in range(k):\n",
    "        file = folder / f\"{i}\" / \"i_list.pickle\"\n",
    "        with open(file, \"rb\") as infile:\n",
    "            results.append(pickle.load(infile))\n",
    "    return results\n",
    "\n",
    "\n",
    "def calc_i(\n",
    "    permutations: Dict, nse_values: Dict, epoch: int = 30, k: int = 5\n",
    ") -> pd.DataFrame:\n",
    "    nse_values = nse_values[f\"epoch_{epoch}\"]\n",
    "    means = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    for i in range(k):\n",
    "        fold = permutations[i]\n",
    "        features = list(fold.keys())\n",
    "        for feature in features:\n",
    "            feature_results = fold[feature]\n",
    "            for k_ in list(feature_results.keys()):\n",
    "                for basin in feature_results[k_].keys():\n",
    "                    feature_results[k_][basin]\n",
    "                    means[feature][basin] += feature_results[k_][basin] / len(\n",
    "                        list(feature_results.keys())\n",
    "                    )\n",
    "    for feature in features:\n",
    "        for basin in means[feature].keys():\n",
    "            means[feature][basin] = nse_values[basin] - means[feature][basin]\n",
    "    return pd.DataFrame.from_dict(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "permutations = parse_results(\n",
    "    \"/home/bernhard/git/Master-Thesis/runs/correlation_reduction/all_features_cv/permutation/\",\n",
    "    k=5,\n",
    ")\n",
    "nse_values = load_cv_results(\n",
    "    main_folder=\"/home/bernhard/git/Master-Thesis/runs/correlation_reduction/all_features_cv/\",\n",
    "    model_type=\"ealstm\",\n",
    "    seed=\"19970204\",\n",
    "    k=5,\n",
    ")\n",
    "importance_all_features = calc_i(permutations, nse_values, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gauge_easting     39036\n",
      "gauge_northing    39036\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-20.826532323937354"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(importance_all_features.idxmin())\n",
    "nse_values[\"epoch_30\"][\"39036\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount i &gt; 0.5</th>\n",
       "      <th>Fraction i &gt; 0.5</th>\n",
       "      <th>Max |i|</th>\n",
       "      <th>i</th>\n",
       "      <th>median(i)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gauge_easting</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0218688</td>\n",
       "      <td>0.709588</td>\n",
       "      <td>|0.0091|+-0.26</td>\n",
       "      <td>0.0105563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gauge_northing</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0298211</td>\n",
       "      <td>0.853332</td>\n",
       "      <td>|-0.0045|+-0.31</td>\n",
       "      <td>0.00707913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Amount i > 0.5 Fraction i > 0.5   Max |i|                i  \\\n",
       "gauge_easting              11        0.0218688  0.709588   |0.0091|+-0.26   \n",
       "gauge_northing             15        0.0298211  0.853332  |-0.0045|+-0.31   \n",
       "\n",
       "                 median(i)  \n",
       "gauge_easting    0.0105563  \n",
       "gauge_northing  0.00707913  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def importance_metrics(importances: pd.DataFrame, limit: float = 0.1) -> pd.DataFrame:\n",
    "    fracs = defaultdict(dict)\n",
    "    for feature in importances.columns:\n",
    "        fracs[feature][f\"Amount i > {limit}\"] = (\n",
    "            importances[feature].abs() > limit\n",
    "        ).sum()\n",
    "        fracs[feature][f\"Fraction i > {limit}\"] = fracs[feature][\n",
    "            f\"Amount i > {limit}\"\n",
    "        ] / len(importances[feature])\n",
    "        fracs[feature][f\"Max |i|\"] = importances[feature].max()\n",
    "        fracs[feature][\n",
    "            \"i\"\n",
    "        ] = f\"|{importances[feature].mean():.4f}|+-{importances[feature].std():.2f}\"\n",
    "        fracs[feature][f\"median(i)\"] = np.median(importances[feature])\n",
    "    return pd.DataFrame.from_dict(fracs).T\n",
    "\n",
    "\n",
    "fracs = importance_metrics(importance_all_features, limit=0.5)\n",
    "fracs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
