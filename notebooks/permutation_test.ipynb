{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Union, Dict, Optional, List\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from camelsml.metrics import calc_nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"../figstyle.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(folder: Union[Path, str], model_type: str, seed: int) -> Dict:\n",
    "    if isinstance(folder, str):\n",
    "        folder = Path(folder)\n",
    "    if not folder.exists():\n",
    "        raise FileNotFoundError(f\"No directory found at {folder}\")\n",
    "    nse_values = defaultdict(dict)\n",
    "    epochs = len(list(folder.rglob(f\"{model_type}_seed{seed}_epoch_*.p\")))\n",
    "    if epochs == 0:\n",
    "        raise FileNotFoundError(f\"No validation runs found\")\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        file = folder / f\"{model_type}_seed{seed}_epoch_{epoch}.p\"\n",
    "        with open(file, \"rb\") as results_file:\n",
    "            results = pickle.load(results_file)\n",
    "        for basin in results.keys():\n",
    "            nse_values[f\"epoch_{epoch}\"][basin] = calc_nse(\n",
    "                obs=results[basin][\"qobs\"].to_numpy(),\n",
    "                sim=results[basin][\"qsim\"].to_numpy(),\n",
    "            )\n",
    "    return nse_values\n",
    "\n",
    "\n",
    "def load_cv_results(\n",
    "    main_folder: Union[Path, str], k, model_type: str, seed: int, epoch: int = 30\n",
    ") -> Dict:\n",
    "    if isinstance(main_folder, str):\n",
    "        main_folder = Path(main_folder)\n",
    "    if not main_folder.exists():\n",
    "        raise FileNotFoundError(f\"No directory found at {main_folder}\")\n",
    "    results = {}\n",
    "    full_results = defaultdict(dict)\n",
    "    for i in tqdm(range(k)):\n",
    "        folder = main_folder / str(i)\n",
    "        folder = list(folder.glob(\"*\"))\n",
    "        if len(folder) != 1:\n",
    "            warnings.warn(f\"Check your file structure in {i}\")\n",
    "        folder = folder[0]\n",
    "        results[i] = load_results(folder, model_type, seed)\n",
    "        for key in list(results[i].keys())[:epoch]:\n",
    "            for basin in results[i][key].keys():\n",
    "                full_results[key][basin] = results[i][key][basin]\n",
    "    return full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(\n",
    "    folder: Union[str, Path], k: int = 5, skip: Optional[Union[int, List[int]]] = None\n",
    ") -> Dict:\n",
    "    if isinstance(skip, int):\n",
    "        skip = [skip]\n",
    "    folder = Path(folder)\n",
    "    results = {}\n",
    "    for i in range(k):\n",
    "        if not skip is None and i in skip:\n",
    "            continue\n",
    "        file = folder / f\"{i}\" / \"i_list.pickle\"\n",
    "        with open(file, \"rb\") as infile:\n",
    "            results[i] = pickle.load(infile)\n",
    "    return results\n",
    "\n",
    "\n",
    "def calc_i(\n",
    "    permutations: List,\n",
    "    nse_values: Dict,\n",
    "    epoch: int = 30,\n",
    "    k: int = 5,\n",
    "    min_nse=0,\n",
    "    skip: Optional[Union[int, List[int]]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    if isinstance(skip, int):\n",
    "        skip = [skip]\n",
    "    features = list(\n",
    "        permutations[list(permutations.keys())[0]].keys()\n",
    "    )  # permutations.keys()[0]])\n",
    "    nse_values = nse_values[f\"epoch_{epoch}\"]\n",
    "    means = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    index = -1\n",
    "    for i in range(k):\n",
    "        if not skip is None and i in skip:\n",
    "            print(f\"skipped {i}!\")\n",
    "            index += 1\n",
    "            continue\n",
    "        else:\n",
    "            index += 1\n",
    "        fold = permutations[index]\n",
    "        # features = list(fold.keys())\n",
    "        for feature in features:\n",
    "            feature_results = fold[feature]\n",
    "            for k_ in list(feature_results.keys()):\n",
    "                # print(k_, len(list(feature_results.keys())))\n",
    "                for basin in feature_results[k_].keys():\n",
    "                    means[feature][basin] += feature_results[k_][basin] / len(\n",
    "                        list(feature_results.keys())\n",
    "                    )\n",
    "\n",
    "    for feature in features:\n",
    "        for basin in means[feature].keys():\n",
    "            if nse_values[basin] >= min_nse:\n",
    "                means[feature][basin] = nse_values[basin] - means[feature][basin]\n",
    "            else:\n",
    "                means[feature][basin] = np.nan\n",
    "    return pd.DataFrame.from_dict(means).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_feature_importance(\n",
    "    importances: pd.DataFrame, features: List[str], ax: Optional[plt.Axes] = None\n",
    "):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "    ax.boxplot(importances[features].values)\n",
    "    ax.set_xticklabels(\n",
    "        [feature.replace(\"_\", \"\\_\") for feature in features], rotation=45\n",
    "    )\n",
    "    # ax.set_yscale(\"log\")\n",
    "    ax.grid(\"on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:18<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "permutations = parse_results(\n",
    "    \"/home/bernhard/git/Master-Thesis/runs/correlation_reduction/all_features_cv/permutation/\",\n",
    "    k=k,\n",
    ")\n",
    "nse_values = load_cv_results(\n",
    "    main_folder=\"/home/bernhard/git/Master-Thesis/runs/correlation_reduction/all_features_cv/\",\n",
    "    model_type=\"ealstm\",\n",
    "    seed=\"19970204\",\n",
    "    k=k,\n",
    ")\n",
    "importance_all_features = calc_i(permutations, nse_values, k=k, min_nse=0.5, epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>95%</th>\n",
       "      <th>75%</th>\n",
       "      <th>Median</th>\n",
       "      <th>25%</th>\n",
       "      <th>5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q95</th>\n",
       "      <td>9.965331</td>\n",
       "      <td>0.423366</td>\n",
       "      <td>0.122163</td>\n",
       "      <td>0.039146</td>\n",
       "      <td>-0.012220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseflow_index_ceh</th>\n",
       "      <td>1.223817</td>\n",
       "      <td>0.213468</td>\n",
       "      <td>0.079608</td>\n",
       "      <td>0.021573</td>\n",
       "      <td>-0.008008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_mean</th>\n",
       "      <td>0.329857</td>\n",
       "      <td>0.112807</td>\n",
       "      <td>0.042575</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>-0.017017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aridity</th>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>-0.021357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5</th>\n",
       "      <td>0.609510</td>\n",
       "      <td>0.059715</td>\n",
       "      <td>0.009635</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>-0.027473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_seasonality</th>\n",
       "      <td>0.118962</td>\n",
       "      <td>0.016138</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>-0.021852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <td>0.113298</td>\n",
       "      <td>0.014959</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>-0.000407</td>\n",
       "      <td>-0.012037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inwater_perc</th>\n",
       "      <td>0.119842</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>-0.001016</td>\n",
       "      <td>-0.020580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elev_10</th>\n",
       "      <td>0.100327</td>\n",
       "      <td>0.015951</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>-0.001558</td>\n",
       "      <td>-0.022612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_prec_dur</th>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.010816</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>-0.001176</td>\n",
       "      <td>-0.020019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gauge_easting</th>\n",
       "      <td>0.052819</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>-0.001804</td>\n",
       "      <td>-0.030719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_prec_freq</th>\n",
       "      <td>0.041511</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>-0.019870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elev_90</th>\n",
       "      <td>0.054371</td>\n",
       "      <td>0.009842</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>-0.001120</td>\n",
       "      <td>-0.016837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elev_50</th>\n",
       "      <td>0.092088</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>-0.000559</td>\n",
       "      <td>-0.015151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conductivity_hypres</th>\n",
       "      <td>0.052615</td>\n",
       "      <td>0.009163</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>-0.001029</td>\n",
       "      <td>-0.030193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grass_perc</th>\n",
       "      <td>0.047833</td>\n",
       "      <td>0.008633</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>-0.001972</td>\n",
       "      <td>-0.022270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urban_perc</th>\n",
       "      <td>0.105542</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>-0.000522</td>\n",
       "      <td>-0.013075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elev_max</th>\n",
       "      <td>0.041182</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>-0.001610</td>\n",
       "      <td>-0.021350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_prec_freq</th>\n",
       "      <td>0.038179</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>-0.002420</td>\n",
       "      <td>-0.023521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pet_mean</th>\n",
       "      <td>0.052650</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>-0.001097</td>\n",
       "      <td>-0.016910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          95%       75%    Median       25%        5%\n",
       "Q95                  9.965331  0.423366  0.122163  0.039146 -0.012220\n",
       "baseflow_index_ceh   1.223817  0.213468  0.079608  0.021573 -0.008008\n",
       "p_mean               0.329857  0.112807  0.042575  0.007947 -0.017017\n",
       "aridity              0.104584  0.036468  0.013234  0.000704 -0.021357\n",
       "Q5                   0.609510  0.059715  0.009635  0.000348 -0.027473\n",
       "p_seasonality        0.118962  0.016138  0.003102 -0.000706 -0.021852\n",
       "area                 0.113298  0.014959  0.002624 -0.000407 -0.012037\n",
       "inwater_perc         0.119842  0.015252  0.002568 -0.001016 -0.020580\n",
       "elev_10              0.100327  0.015951  0.002489 -0.001558 -0.022612\n",
       "low_prec_dur         0.061404  0.010816  0.002300 -0.001176 -0.020019\n",
       "gauge_easting        0.052819  0.009663  0.001680 -0.001804 -0.030719\n",
       "low_prec_freq        0.041511  0.008029  0.001656 -0.002004 -0.019870\n",
       "elev_90              0.054371  0.009842  0.001635 -0.001120 -0.016837\n",
       "elev_50              0.092088  0.010309  0.001416 -0.000559 -0.015151\n",
       "conductivity_hypres  0.052615  0.009163  0.001395 -0.001029 -0.030193\n",
       "grass_perc           0.047833  0.008633  0.001357 -0.001972 -0.022270\n",
       "urban_perc           0.105542  0.009705  0.001275 -0.000522 -0.013075\n",
       "elev_max             0.041182  0.006633  0.001120 -0.001610 -0.021350\n",
       "high_prec_freq       0.038179  0.006683  0.001058 -0.002420 -0.023521\n",
       "pet_mean             0.052650  0.008668  0.000962 -0.001097 -0.016910"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def importance_metrics(importances: pd.DataFrame) -> pd.DataFrame:\n",
    "    fracs = defaultdict(dict)\n",
    "    for feature in importances.columns:\n",
    "        # fracs[feature][f\"Amount i > {limit}\"] = (importances[feature] > limit).sum()\n",
    "        # fracs[feature][f\"Fraction i > {limit}\"] = fracs[feature][\n",
    "        #    f\"Amount i > {limit}\"\n",
    "        # ] / len(importances[feature])\n",
    "        # fracs[feature][f\"Max\"] = importances[feature].max()\n",
    "        # fracs[feature][\n",
    "        #    \"|i|\"\n",
    "        # ] = f\"{importances[feature].mean():.4f}+-{importances[feature].std():.2f}\"\n",
    "        fracs[feature][\"95%\"] = np.percentile(importances[feature], q=95)\n",
    "        fracs[feature][\"75%\"] = np.percentile(importances[feature], q=75)\n",
    "        fracs[feature][\"Median\"] = np.median(importances[feature])\n",
    "        fracs[feature][\"25%\"] = np.percentile(importances[feature], q=25)\n",
    "        fracs[feature][\"5%\"] = np.percentile(importances[feature], q=5)\n",
    "    # df = pd.DataFrame.from_dict(fracs).T.sort_values(\n",
    "    #    f\"Fraction i > {limit}\", ascending=False\n",
    "    # )\n",
    "    df = pd.DataFrame.from_dict(fracs).T.sort_values(\"Median\", ascending=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "fracs_all_features = importance_metrics(importance_all_features)\n",
    "folder = Path(\"../doc/thesis/tables/results_section\")\n",
    "folder.mkdir(parents=True, exist_ok=True)\n",
    "fracs_all_features.drop(fracs_all_features.index[20:]).to_latex(\n",
    "    folder / \"overfit_importance.tex\", float_format=\"%.2f\"\n",
    ")\n",
    "fracs_all_features.drop(fracs_all_features.index[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig, axes = plt.subplots(2, 2, sharex=True, sharey=False, figsize=[4.7747, 4.7747])\\naxes = axes.flatten()\\n\\nfeatures = [\"Q95\", \"baseflow_index_ceh\", \"porosity_hypres_5\", \"num_reservoir\"]\\n\\nsave_path = Path(\"../doc/thesis/figures/permutation/all_features_cv\")\\nsave_path.mkdir(exist_ok=True, parents=True)\\n\\nfor i, feature in enumerate(features):\\n    plot_importances(importance_all_features, feature, ax=axes[i])\\n    print(\\n        feature.replace(\"_\", \"\\\\_\"),\\n        feature.replace(\"_\", \"\\\\_\").encode(encoding=\"UTF-8\"),\\n    )\\n    axes[i].set_title(feature.replace(\"_\", \"\\\\_\"))\\n    axes[i].grid()\\nfig.tight_layout()\\nmatplotlib.use(\"pgf\")\\nmatplotlib.rcParams.update(\\n    {\\n        \"pgf.texsystem\": \"pdflatex\",\\n        \"font.family\": \"serif\",\\n        \"text.usetex\": True,\\n        \"pgf.rcfonts\": False,\\n    }\\n)\\nfig.savefig(save_path / \"histogram_all.pgf\")\\nfig.savefig(save_path / \"histogram_all.pdf\")\\n# plt.show()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_importances(\n",
    "    importances: pd.DataFrame,\n",
    "    feature: str,\n",
    "    ax: Optional[plt.Axes] = None,\n",
    "    color: str = \"blue\",\n",
    "    label: Optional[str] = None,\n",
    "):\n",
    "    x = importances[feature][importances[feature] <= 1]\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "    ax.hist(x, facecolor=color, bins=100, density=True, label=label)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=False, figsize=[4.7747, 4.7747])\n",
    "axes = axes.flatten()\n",
    "\n",
    "features = [\"Q95\", \"baseflow_index_ceh\", \"porosity_hypres_5\", \"num_reservoir\"]\n",
    "\n",
    "save_path = Path(\"../doc/thesis/figures/permutation/all_features_cv\")\n",
    "save_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    plot_importances(importance_all_features, feature, ax=axes[i])\n",
    "    print(\n",
    "        feature.replace(\"_\", \"\\\\_\"),\n",
    "        feature.replace(\"_\", \"\\\\_\").encode(encoding=\"UTF-8\"),\n",
    "    )\n",
    "    axes[i].set_title(feature.replace(\"_\", \"\\_\"))\n",
    "    axes[i].grid()\n",
    "fig.tight_layout()\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update(\n",
    "    {\n",
    "        \"pgf.texsystem\": \"pdflatex\",\n",
    "        \"font.family\": \"serif\",\n",
    "        \"text.usetex\": True,\n",
    "        \"pgf.rcfonts\": False,\n",
    "    }\n",
    ")\n",
    "fig.savefig(save_path / \"histogram_all.pgf\")\n",
    "fig.savefig(save_path / \"histogram_all.pdf\")\n",
    "# plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above results seem to imply that the EA-LSTM model likes extra precipitation info.\n",
    "Possibly because the timeseries do not contain enough information? Or maybe sequence_length should be increased?\n",
    "\n",
    "## The results below indicate that not many basins care about the \"physical\" features\n",
    "This is model dependent, will do the same analysis of the reduced model to see if this is still the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Amount i > 0.1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-880cfd3177cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"dpsbar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchosen_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"dom_land_cover\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ]\n\u001b[0;32m----> 8\u001b[0;31m fracs_all_features.loc[chosen_features, :].sort_values(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"Amount i > 0.1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Master-Thesis-A3SnfaSZ/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   5296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5297\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5298\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5300\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Master-Thesis-A3SnfaSZ/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Amount i > 0.1'"
     ]
    }
   ],
   "source": [
    "chosen_features = np.genfromtxt(\n",
    "    \"../runs/correlation_reduction/chosen_features/use_features.txt\", dtype=\"str\"\n",
    ")\n",
    "# BUG!!\n",
    "chosen_features = chosen_features[\n",
    "    np.logical_and(chosen_features != \"dpsbar\", chosen_features != \"dom_land_cover\")\n",
    "]\n",
    "fracs_all_features.loc[chosen_features, :].sort_values(\n",
    "    \"Amount i > 0.1\", ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fig, axes = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "features = [\"area\", \"elev_10\", \"elev_50\", \"urban_perc\"]\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    plot_importances(importance_all_features, feature, ax=axes[i])\n",
    "    axes[i].set_title(feature.replace(\"_\", \"\\_\"))\n",
    "    axes[i].grid()\n",
    "# fig.tight_layout()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of reduced, physically based system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "permutations_chosen_features = parse_results(\n",
    "    \"/home/bernhard/git/Master-Thesis/runs/correlation_reduction/chosen_features_cv/permutation/\",\n",
    "    k=k,\n",
    ")\n",
    "nse_values_chosen_features = load_cv_results(\n",
    "    main_folder=\"/home/bernhard/git/Master-Thesis/runs/correlation_reduction/chosen_features_cv/\",\n",
    "    model_type=\"ealstm\",\n",
    "    seed=\"19970204\",\n",
    "    k=k,\n",
    "    epoch=13,\n",
    ")\n",
    "importance_chosen_features = calc_i(\n",
    "    permutations_chosen_features, nse_values_chosen_features, k=k, min_nse=0.5, epoch=13\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs_chosen_features = importance_metrics(importance_chosen_features, limit=0.1)\n",
    "fracs_chosen_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fig, axes = plt.subplots(\n",
    "    2, 2, sharex=True, sharey=False, figsize=[10, 10]\n",
    ")  # , figsize=[4.7747, 4.7747])\n",
    "axes = axes.flatten()\n",
    "\n",
    "features = [\"inwater_perc\", \"no_gw_perc\", \"area\", \"nsig_low_perc\"]\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    plot_importances(\n",
    "        importance_chosen_features, feature, ax=axes[i], color=\"blue\", label=\"Chosen\"\n",
    "    )\n",
    "    plot_importances(\n",
    "        importance_all_features, features, ax=axes[i], color=\"red\", label=\"All\"\n",
    "    )\n",
    "    axes[i].legend()\n",
    "    axes[i].set_title(feature.replace(\"_\", \"\\_\"))\n",
    "    axes[i].grid()\n",
    "fig.tight_layout()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of fixed all feature run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "permutations_all_features_fixed = parse_results(\n",
    "    \"/home/bernhard/git/Master-Thesis/runs/correlation_reduction/all_features_fixed_cv/permutation/\",\n",
    "    k=k,\n",
    ")\n",
    "nse_values_all_features_fixed = load_cv_results(\n",
    "    main_folder=\"/home/bernhard/git/Master-Thesis/runs/correlation_reduction/all_features_fixed_cv/\",\n",
    "    model_type=\"ealstm\",\n",
    "    seed=\"19970204\",\n",
    "    k=k,\n",
    "    epoch=20,\n",
    ")\n",
    "importance_all_features_fixed = calc_i(\n",
    "    permutations_all_features_fixed,\n",
    "    nse_values_all_features_fixed,\n",
    "    k=k,\n",
    "    min_nse=0.7,\n",
    "    epoch=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs_all_features_fixed = importance_metrics(importance_all_features_fixed, limit=0.1)\n",
    "fracs_all_features_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fig, axes = plt.subplots(\n",
    "    2, 2, sharex=True, sharey=False, figsize=[10, 10]\n",
    ")  # , figsize=[4.7747, 4.7747])\n",
    "axes = axes.flatten()\n",
    "\n",
    "features = [\"inwater_perc\", \"frac_high_perc\", \"clay_perc\", \"low_nsig_perc\"]\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    plot_importances(\n",
    "        importance_chosen_features, feature, ax=axes[i], color=\"blue\", label=\"Chosen\"\n",
    "    )\n",
    "    plot_importances(\n",
    "        importance_all_features_fixed, features, ax=axes[i], color=\"red\", label=\"All\"\n",
    "    )\n",
    "    axes[i].legend()\n",
    "    axes[i].set_title(feature.replace(\"_\", \"\\_\"))\n",
    "    axes[i].grid()\n",
    "    axes[i].set_yscale(\"log\")\n",
    "fig.tight_layout()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance CAMELS-US vs CAMELS-GB\n",
    "### CAMELS-US:\n",
    "\n",
    "There is a bug in the permutation test code that caused the test to skip root_depth in camels-us..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "permutations_common_features_us = parse_results(\n",
    "    \"/home/bernhard/git/Master-Thesis/runs/camels_us/chosen_features_cv_us/permutation/\",\n",
    "    k=k,\n",
    ")\n",
    "nse_values_common_features_us = load_cv_results(\n",
    "    main_folder=\"/home/bernhard/git/Master-Thesis/runs/camels_us/chosen_features_cv_us/\",\n",
    "    model_type=\"ealstm\",\n",
    "    seed=\"19970204\",\n",
    "    k=k,\n",
    "    epoch=20,\n",
    ")\n",
    "importance_common_features_us = calc_i(\n",
    "    permutations_common_features_us,\n",
    "    nse_values_common_features_us,\n",
    "    k=k,\n",
    "    min_nse=0.7,\n",
    "    epoch=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs_common_features_us = importance_metrics(importance_common_features_us)\n",
    "fracs_common_features_us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAMELS-GB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "permutations_common_features_gb = parse_results(\n",
    "    \"/home/bernhard/git/Master-Thesis/runs/camels_us/chosen_features_cv_gb/permutation/\",\n",
    "    k=k,\n",
    ")\n",
    "nse_values_common_features_gb = load_cv_results(\n",
    "    main_folder=\"/home/bernhard/git/Master-Thesis/runs/camels_us/chosen_features_cv_gb/\",\n",
    "    model_type=\"ealstm\",\n",
    "    seed=\"19970204\",\n",
    "    k=k,\n",
    "    epoch=20,\n",
    ")\n",
    "importance_common_features_gb = calc_i(\n",
    "    permutations_common_features_gb,\n",
    "    nse_values_common_features_gb,\n",
    "    k=k,\n",
    "    min_nse=0.7,\n",
    "    epoch=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs_common_features_gb = importance_metrics(importance_common_features_gb, limit=0.1)\n",
    "fracs_common_features_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fig, axes = plt.subplots(\n",
    "    5, 2, sharex=True, sharey=False, figsize=[10, 30]\n",
    ")  # , figsize=[4.7747, 4.7747])\n",
    "axes = axes.flatten()\n",
    "\n",
    "features = {\n",
    "    \"root_depth\": \"missing\",\n",
    "    \"clay_perc\": \"clay_frac\",\n",
    "    \"conductivity_cosby\": \"soil_conductivity\",\n",
    "    \"elev_50\": \"elev_mean\",\n",
    "    \"organic_perc\": \"organic_frac\",\n",
    "    \"inwater_perc\": \"water_frac\",\n",
    "    \"area\": \"area_gages2\",\n",
    "    \"silt_perc\": \"silt_frac\",\n",
    "    \"sand_perc\": \"sand_frac\",\n",
    "    \"soil_depth_pelletier\": \"soil_depth_pelletier\",\n",
    "}\n",
    "\n",
    "for i, feature in enumerate(features.keys()):\n",
    "    plot_importances(\n",
    "        importance_common_features_gb, feature, ax=axes[i], color=\"blue\", label=\"GB\"\n",
    "    )\n",
    "    axes[i].set_title(\n",
    "        f\"{feature} (GB), missing in US because of NaN\".replace(\"_\", \"\\_\")\n",
    "    )\n",
    "    try:\n",
    "        plot_importances(\n",
    "            importance_common_features_us,\n",
    "            features[feature],\n",
    "            ax=axes[i],\n",
    "            color=\"red\",\n",
    "            label=\"US\",\n",
    "        )\n",
    "        axes[i].set_title(\n",
    "            f\"{feature} (GB), {features[feature]} (US)\".replace(\"_\", \"\\_\")\n",
    "        )\n",
    "    except KeyError:\n",
    "        print(f\"Skipped {feature} in CAMELS-US\")\n",
    "    axes[i].legend()\n",
    "\n",
    "    axes[i].grid()\n",
    "    # axes[i].set_yscale(\"log\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kratzert third paper features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "permutations_kratzert_features_us = parse_results(\n",
    "    \"/home/bernhard/git/Master-Thesis/runs/camels_us/kratzert_features_cv_us/permutation/\",\n",
    "    k=k,\n",
    ")\n",
    "\n",
    "nse_values_kratzert_features_us = load_cv_results(\n",
    "    main_folder=\"/home/bernhard/git/Master-Thesis/runs/camels_us/kratzert_features_cv_us/\",\n",
    "    model_type=\"lstm\",\n",
    "    seed=\"19970204\",\n",
    "    k=k,\n",
    "    epoch=13,\n",
    ")\n",
    "importance_kratzert_features_us = calc_i(\n",
    "    permutations_kratzert_features_us,\n",
    "    nse_values_kratzert_features_us,\n",
    "    k=k,\n",
    "    min_nse=0.5,\n",
    "    epoch=13,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs_kratzert_features_us = importance_metrics(importance_kratzert_features_us)\n",
    "fracs_kratzert_features_us.to_latex(\n",
    "    folder / \"kratzert_features_importance.tex\", float_format=\"%.2f\"\n",
    ")\n",
    "fracs_kratzert_features_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "boxplot_feature_importance(\n",
    "    importances=importance_kratzert_features_us,\n",
    "    features=[\n",
    "        \"frac_snow\",\n",
    "        \"elev_mean\",\n",
    "        \"aridity\",\n",
    "        \"max_water_content\",\n",
    "        \"carbonate_rocks_frac\",\n",
    "    ],\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_ylim([-0.1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fracs_kratzert_features_us = importance_metrics(\n",
    "    importance_kratzert_features_us, limit=0.1\n",
    ")\n",
    "fracs_kratzert_features_us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on feature importances\n",
    "Kratzert et al did not run a static feature importance analysis on the third paper (the one with testing on ungauged basins). On the second paper when he ran a feature importance analysis he observed that mean precipitation was the most important feature. To me this could in theory imply that the gauged basin model uses the mean precipitation as a simple way to \"recognize\" each basin (this possibility Felix mentioned earlier too). My results here indicate that the snow fraction is more important than in Kratzert's analysis. What these results do agree with however is that hydrological information is more important than land coverage and soil attributes. A bit dissapointing for physical understanding, perhaps? Could always train a new model without these hydrological features to see how that performs, though!\n",
    "\n",
    "Also, the fact that static information about precipitation like high_prec_frec is still deemed important to me implies that there is potential for improving our LSTM model in the future. All that information should be able to be taken from the time series, implying to me that the LSTM has potential to learn more time dependencies than it does now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined dataset. Some notes.\n",
    "\n",
    "* Times series are differnent. Only 3 in common. (I use 6 right now for CAMELS-GB, Kratzert uses 5 for CAMELS-US)\n",
    "    - This I already knew though, and it would be interesting to look at a reduced set of itme series anyway.\n",
    "* Land coverage information is structured differently. \n",
    "    - CAMELS-US only has fractions for the dominant land cover for each basin. CAMELS-GB has much more information here as it contains fractions from several land covers.\n",
    "* There are some attributes I think could be comparable to each other. \n",
    "    - |CAMELS-US | CAMELS-GB |\n",
    "      |-------------------|-----------------|\n",
    "      |sand_frac|sand_perc|\n",
    "      |silt_frac|silt_perc|\n",
    "      |clay_frac|clay_perc|\n",
    "      |organic_frac|organic_perc|\n",
    "      |max_water_content|tawc (unsure)|\n",
    "      |root_depth_XX|root_depth (Both are available as percentiles)|\n",
    "      |soil_depth_pelletier|soil_depth_pelletier|\n",
    "      |soil_conductivity|conductivity_(hypres or cosby?)|\n",
    "      |soil_porosity|soil_porosity_(hypres or cosby?)|\n",
    "      |||\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camels US: Dominating land cover [string],   CAMELS GB: all land covers\n",
    "           coverage fraction of dominating,  coverage fraction of several types\n",
    "           \n",
    "This leads to:\n",
    "\n",
    "1: The model gets the fraction of dominating, but no context for it.\n",
    "\n",
    "2: Same as above, but also include land cover type as input (this input is non-numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "permutations_mixed = parse_results(\n",
    "    \"/home/bernhard/git/Master-Thesis/runs/combined_dataset/mixed/permutation/\",\n",
    "    k=k,\n",
    ")\n",
    "nse_values_mixed = load_cv_results(\n",
    "    main_folder=\"/home/bernhard/git/Master-Thesis/runs/combined_dataset/mixed/\",\n",
    "    model_type=\"ealstm\",\n",
    "    seed=\"19970204\",\n",
    "    k=k,\n",
    "    epoch=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_i_transfer(\n",
    "    permutations: List,\n",
    "    nse_values: Dict,\n",
    "    epoch: int = 30,\n",
    "    k: int = 5,\n",
    "    min_nse=0,\n",
    "    skip: Optional[Union[int, List[int]]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    if isinstance(skip, int):\n",
    "        skip = [skip]\n",
    "    if isinstance(skip, list):\n",
    "        dividor = k - len(skip)\n",
    "    else:\n",
    "        dividor = k\n",
    "    nse_values = nse_values[f\"epoch_{epoch}\"]\n",
    "    means = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    index = -1\n",
    "    for i in range(k):\n",
    "        if not skip is None and i in skip:\n",
    "            print(f\"skipped {i}!\")\n",
    "            continue\n",
    "        else:\n",
    "            index += 1\n",
    "        fold = permutations[index]\n",
    "        features = list(fold.keys())\n",
    "        for feature in features:\n",
    "            feature_results = fold[feature]\n",
    "            for k_ in list(feature_results.keys()):\n",
    "                for basin in feature_results[k_].keys():\n",
    "                    feature_results[k_][basin]\n",
    "                    means[feature][basin] += feature_results[k_][basin] / (\n",
    "                        len(list(feature_results.keys())) * dividor\n",
    "                    )\n",
    "        for feature in features:\n",
    "            for basin in means[feature].keys():\n",
    "                if nse_values[basin] >= min_nse:\n",
    "                    means[feature][basin] = nse_values[basin] - means[feature][basin]\n",
    "                else:\n",
    "                    means[feature][basin] = np.nan\n",
    "\n",
    "    return pd.DataFrame.from_dict(means).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_mixed = calc_i(\n",
    "    permutations_mixed,\n",
    "    nse_values_mixed,\n",
    "    k=k,\n",
    "    min_nse=0,\n",
    "    epoch=30,\n",
    ")\n",
    "importance_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs_mixed = importance_metrics(importance_mixed, limit=0.1)\n",
    "fracs_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_importances(importance_mixed: pd.DataFrame) -> pd.DataFrame:\n",
    "    importance_us = importance_mixed[importance_mixed.index.str.contains(\"us\")]\n",
    "    importance_gb = importance_mixed[importance_mixed.index.str.contains(\"gb\")]\n",
    "    return importance_us, importance_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_mixed_us, importance_mixed_gb = split_importances(importance_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs_mixed_us = importance_metrics(importance_mixed_us, limit=0.1)\n",
    "fracs_mixed_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs_mixed_gb = importance_metrics(importance_mixed_gb, limit=0.1)\n",
    "fracs_mixed_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "permutations_train_us_val_gb_no_organic_no_gvf = parse_results(\n",
    "    \"/home/bernhard/git/Master-Thesis/runs/combined_dataset/train_us_val_gb_no_organic_no_gvf/permutation/\",\n",
    "    k=k,\n",
    ")\n",
    "\n",
    "nse_values_train_us_val_gb_no_organic_no_gvf = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for i in tqdm(range(k)):  # (range(1, 3)):  # Remember to fix\n",
    "    results_ = load_results(\n",
    "        folder=f\"/home/bernhard/git/Master-Thesis/runs/combined_dataset/train_us_val_gb_no_organic_no_gvf/val_gb/{i}\",\n",
    "        model_type=\"ealstm\",\n",
    "        seed=\"19970204\",\n",
    "    )\n",
    "    for epoch in results_:\n",
    "        for basin in results_[epoch]:\n",
    "            nse_values_train_us_val_gb_no_organic_no_gvf[epoch][basin] += (\n",
    "                results_[epoch][basin] / k\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_train_us_val_gb_no_organic_no_gvf = calc_i_transfer(\n",
    "    permutations_train_us_val_gb_no_organic_no_gvf,\n",
    "    nse_values_train_us_val_gb_no_organic_no_gvf,\n",
    "    k=k,\n",
    "    min_nse=0.5,\n",
    "    epoch=14,\n",
    ")\n",
    "importance_train_us_val_gb_no_organic_no_gvf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs_train_us_val_gb_no_organic_no_gvf = importance_metrics(\n",
    "    importance_train_us_val_gb_no_organic_no_gvf, limit=0.6\n",
    ")\n",
    "fracs_train_us_val_gb_no_organic_no_gvf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "permutations_all_features_concat_seq_len_gb = parse_results(\n",
    "    \"/home/bernhard/git/Master-Thesis/runs/correlation_reduction/all_features_concat_seq_len_cv/permutation/\",\n",
    "    k=k,\n",
    ")\n",
    "\n",
    "\n",
    "nse_values_common_features_gb = load_cv_results(\n",
    "    main_folder=\"/home/bernhard/git/Master-Thesis/runs/correlation_reduction/all_features_concat_seq_len_cv/\",\n",
    "    model_type=\"lstm\",\n",
    "    seed=\"19970204\",\n",
    "    k=k,\n",
    "    epoch=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_all_features_concat_seq_len_cv = calc_i(\n",
    "    permutations_all_features_concat_seq_len_gb,\n",
    "    nse_values_common_features_gb,\n",
    "    k=k,\n",
    "    min_nse=0.5,\n",
    "    epoch=15,\n",
    ")\n",
    "importance_all_features_concat_seq_len_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs_all_features_concat_seq_len_cv = importance_metrics(\n",
    "    importance_all_features_concat_seq_len_cv\n",
    ")\n",
    "folder = Path(\"../doc/thesis/tables/results_section\")\n",
    "folder.mkdir(parents=True, exist_ok=True)\n",
    "fracs_all_features_concat_seq_len_cv.drop(\n",
    "    fracs_all_features_concat_seq_len_cv.index[20:]\n",
    ").to_latex(folder / \"all_features_concat_seq_len_importance.tex\", float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "boxplot_feature_importance(\n",
    "    importances=importance_all_features_concat_seq_len_cv,\n",
    "    features=[\n",
    "        \"low_prec_dur\",\n",
    "        \"low_prec_freq\",\n",
    "        \"tawc\",\n",
    "        \"no_gw_perc\",\n",
    "        \"inter_high_perc\",\n",
    "        \"num_reservoir\",\n",
    "    ],\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_ylim([-0.1, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "permutations_mixed_concat = parse_results(\n",
    "    \"/home/bernhard/git/Master-Thesis/runs/combined_dataset/mixed_concat/permutation/\",\n",
    "    k=k,\n",
    ")\n",
    "\n",
    "\n",
    "nse_values_mixed_concat = load_cv_results(\n",
    "    main_folder=\"/home/bernhard/git/Master-Thesis/runs/combined_dataset/mixed_concat\",\n",
    "    model_type=\"lstm\",\n",
    "    seed=\"19970204\",\n",
    "    k=k,\n",
    "    epoch=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_mixed_concat = calc_i(\n",
    "    permutations_mixed_concat,\n",
    "    nse_values_mixed_concat,\n",
    "    k=k,\n",
    "    min_nse=0.5,\n",
    "    epoch=15,\n",
    ")\n",
    "importance_mixed_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_metrics_mixed(importances: pd.DataFrame) -> pd.DataFrame:\n",
    "    gb = importances.loc[importances.index.str.contains(\"gb_\")]\n",
    "    us = importances.loc[importances.index.str.contains(\"us_\")]\n",
    "    us = importance_metrics(importances=us)\n",
    "    gb = importance_metrics(importances=gb)\n",
    "    mixed = (\n",
    "        pd.concat({\"GB\": gb, \"US\": us}, axis=1)\n",
    "        .swaplevel(0, 1, axis=1)\n",
    "        .sort_index(axis=1)\n",
    "    )\n",
    "    mixed = mixed[[\"95%\", \"75%\", \"Median\", \"25%\", \"5%\"]]\n",
    "    return mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs_mixed_concat = importance_metrics_mixed(importance_mixed_concat)\n",
    "folder = Path(\"../doc/thesis/tables/results_section\")\n",
    "folder.mkdir(parents=True, exist_ok=True)\n",
    "fracs_mixed_concat.to_latex(\n",
    "    folder / \"mixed_concat_importance.tex\",\n",
    "    float_format=\"%.2f\",\n",
    "    multicolumn_format=\"c\",\n",
    ")\n",
    "fracs_mixed_concat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
