\section{Summary}
Our results highlight the hidden potential of machine learning applied for prediction 
in time dependent physical systems. We show that it is possible to mix the information 
in more than one large scale hydrologic dataset to create a more universally fitting 
model. 

As the performance and generalizability of LSTM models used for hydrological 
modelling continues to show its merit, we hope they can be used to supplement 
traditional models.
\section{Future Work}
Building from the work in this thesis there are several ways forward. We believe 
these ways forward can be categorized into two categories:
\begin{enumerate}
    \item Focus on improved machine learning results. If one is more interested in results than in understanding the underlying physics, this is the way forward. Some strategies could be:
    \begin{itemize}
        \item As mentioned several times in this thesis the only way to show that a machine learning model performs well in a specific use case is to do extensive empiric research. This means that a similar analysis needs to be performed on similar data from different sources. Going further with this would then mean to find or create a new dataset with different data sources than \citet{CAMELS_GB} or \citet{CAMELS_US}. During the initial research phase of this thesis we discovered that there was an effort in Chile to create a similar dataset \citep{CAMELS_CL}. The dataset did not seem to be of the same quality as what was used in this thesis so we decided it was out of scope to try and manage that as well.
        \item The scope of this thesis work was limited to LSTM models only. LSTM models have as mentioned in chapter \ref{LSTM drawbacks} some drawbacks that could lead one into trying a different machine learning model. Lately Convolutional Neural Networks (CNNs), which usually are used for image analysis, have shown promising results on time series data as well. \citationneeded CNNs are much more parallelizable algorithms than RNNs \citationneeded and could prove to be more efficient at doing training and prediction.
        \item In addition to CNNs, the field of natural language processing has now shifted some of the focus on LSTMs away in favour of a type of machine learning models known as Transformers \citep{transformers}. This is also to better model long-term dependencies without the computational limitations of recurrent neural networks.
        \item An often overlooked but in fact very important aspect of machine learning models is the tuning of hyperparameters. As mentioned in \ref{Method Drawbacks or something} the approach in this thesis is perhaps not thorough enough. To the author's best knowledge the best way to tune hyperpameters is in fact using a method called nested cross validation \citationneeded. This would take too long to train to be a viable approach for our work, but should be looked into in the future.
    \end{itemize}
	\item Focus on Physics. The results of this thesis are together with works such as \citet{lstm_first_paper}, \citet{lstm_second_paper} and \citet{lstm_third_paper} indicators of the possibility for using data science to better understand the relationships between easily obtainable metadata and the physics of hydrological models.
	\begin{itemize}
		\item Reducing the scope of the machine learning model to model a small effect in a classical physics-based hydrological model instead of modelling the entire system could be a way to better analyze a specific effect. Implementing the modelling of melting frozen soil, which is a physical effect currently not very well understood, could for example be a good place to start. The reason this was not tried in this thesis is that it likely requires gradients of a physical model, as this melting effect is used further down in a model. This either significantly slows down training because of a large use of automatic differentiation or requires numerical derivation, which could lead to instability.
		\item A simpler way of hybrid modelling that we wish we had the time for in this thesis could be to "model the error". This means training a model with a modified cost function where it also takes the input from a physical model. This could give a better indication of what information in the data is the most important and not properly utilized in traditional models. A simple illustration of this concept is shown in Figure \ref{figure simple hybrid}. A good place to start here would be on the CAMELS dataset, as it already contains model outputs from SAC-SMA and other (?) models \citep{CAMELS_US}. To get out of sample predictions one would have to run the traditional models themselves, though, as the dataset only contains predictions on in sample basins split time series-wise.
	\end{itemize}
\end{enumerate}
