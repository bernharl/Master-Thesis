In this chapter we present the results relevant to our discussed topics in the 
next chapter. To keep this chapter structured in a way that makes it easy to 
look up we divide our results into five main sections presenting model importance 
and feature importance for four cases:
\begin{enumerate}
    \item Models trained on CAMELS-GB \citep{CAMELS_GB}.
    \item Models trained on CAMELS \citep{CAMELS_US} in addition to traditional 
        models provided by \citet{CAMELS_hydroshare} and \citet{NWMbench}.
    \item Models trained on a dataset comprised of both CAMELS and CAMELS-GB.
    \item Models trained on CAMELS and validated on CAMELS-GB (notated as US$\rightarrow$GB) 
        and vice-versa.
    \item Models refit on the full train set and validated on the previously excluded 
        test set.
\end{enumerate}
\section{Models trained on CAMELS-GB}
\label{CAMELS-GB results}
In this section we present the results related to model selection and feature 
importance when training and predicting on CAMELS-GB \citep{CAMELS_GB}. To act 
as a proof of concept of the feature importance method described in Chapter 
\ref{Feature selection}, we also include results from an additional model which
is trained on a superset of attribute subset \textbf{\textit{a}} which includes 
attributes directly derived from the observed outcome. We label this model "Overfit model". 
By "attributes", we are referring to the static attributes included in CAMELS and 
CAMELS-GB.

\subsection{Performance}
\begin{figure}
    \centering
    \includegraphics{{results_section/camels_gb/cdf_val}.pdf}
    \caption[CDF plot of CAMELS-GB models.]{Cumulative distribution function of the NSE score of LSTM models trained 
    on CAMELS-GB \citep{CAMELS_GB}. "Overfit model" is a model deliberately trained 
    using static basin attributes derived from the runoff time series of the basins. 
    The other models are described in Table \ref{all models}.}
    \label{CAMELS-GB CDF validation}
\end{figure}
Figure \ref{CAMELS-GB CDF validation} shows the performance of GB$_\text{lstm, all}$, 
GB$_\text{ea-lstm, all}$, GB$_\text{lstm, chosen}$, GB$_\text{ea-lstm, chosen}$ and 
GB$_\text{lstm, none}$ 
trained on CAMELS-GB \citep{CAMELS_GB}. For an overview of these 
LSTM models, see Table \ref{all models}. The overfit model is trained on 
attribute subset \textbf{\textit{a}} in Table \ref{attribute table} in addition 
to attributes directly derived from the observed outcome.
The overfit model significantly outperforms all other models.
 Of the other models there seems to be generally two levels of 
performance. The models using attribute subsets \textbf{\textit{a}} and \textbf{\textit{b}} 
perform similarly, although in the favour of attribute subset \textbf{\textit{a}}, while 
the models trained with no attributes in general perform worse. 
There seems to be little overall difference in performance between EA-LSTM and 
LSTM models, apart from $GB_{lstm, all}$ which performs with a negative NSE value 
for a smaller fraction of the basins.
 All other ungauged  models perform with a negative NSE value for 
approximately 10\% of the basins.

\begin{figure}
    \centering
    \includegraphics{results_section/camels_gb/prediction_best_all_concat_seq_len_cv.pdf}
    \caption[The Highest scoring CAMELS-GB prediction.]{Highest scoring prediction on the validation set  made using 
    GB$_\text{lstm, all}$ compared to the observed outcome. "Obs" is observed runoff, 
    "Sim" is predicted runoff. The basin data is taken from CAMELS-GB \citep{CAMELS_GB}.}
    \label{best prediction all concat seq len}
\end{figure}
The highest scoring validation set prediction made using GB$_\text{lstm, all}$ is 
shown in Figure \ref{best prediction all concat seq len}. It has an NSE score of $\approx 0.96$. 
Most of the peaks are undervalued by the prediction made by the model.
\subsection{Importance}
\begin{table}
    \centering
    \caption[Top 20 overfit CAMELS-GB attributes.]{Top 20 (ranked by median importance) attributes of the overfit model described earlier 
    in this section according to the permutation test. The columns are percentiles.}
    \input{{tables/results_section/overfit_importance}.tex}
    \label{overfit table}
\end{table}
Table \ref{overfit table} shows 5th, 25th, 50th, 75th and 95th percentiles of the 
importances of the top 20 basin attributes of the overfit model according to the 
permutation test described in Chapter \ref{Feature selection}. We observe that the 
attribute with the highest importance in all quantiles is \texttt{Q95}, which is the 
95th percentile runoff derived from the observed runoff time series. \texttt{Q95} has an 
importance of at least 0.05 for 75\% of the basins in the training set. At the 
second spot we have \texttt{baseflow\_index\_ceh}. This attribute has median and 25th percentile 
importances similar to those of \texttt{Q95}, but is significantly less important for 25\% 
of the basins in the training set.
\begin{table}
    \centering
    \caption[Top 20 CAMELS-GB attributes.]{Top 20 (ranked by median importance) attributes of GB$_\text{lstm, all}$ 
    according to the permutation test. The columns are percentiles.}
    \input{{tables/results_section/all_features_concat_seq_len_importance}.tex}
    \label{all concat table}
\end{table}

The top 20 importances found by US$_\text{lstm, all}$ (cross validated) using the permutation test 
are shown in Table \ref{all concat table}. The top two attributes are \texttt{low\_prec\_dur} 
and \texttt{low\_prec\_freq}. These have significantly higher 75th percentile and upward 
importances than all other attributes. The third most important attribute is 
\texttt{tawc} and has a 75th percentile importance that is roughly half of the above ranked 
attribute. The highest ranked attribute has an importance of 0.09 for 25\% of the 
basins in the training set. Of these 20 attributes seven (\texttt{low\_prec\_dur}, \texttt{low\_prec\_frec}, 
\texttt{high\_prec\_frec}, \texttt{p\_seasonality}, \texttt{frac\_snow}, \texttt{p\_mean}, \texttt{high\_prec\_dur}) are climatic indices 
derived from the time series the model is trained on. The attribute \texttt{aridity} is also a climatic indice, 
but is not based on any time series accessed by the model. Three attributes (\texttt{grass\_perc}, 
\texttt{crop\_perc, inwater\_perc}) are land cover attributes. Three attributes (\texttt{tawc}, 
\texttt{root\_depth}, \texttt{conductivity\_hypres}) are soil attributes. Four attributes (\texttt{elev\_90},
\texttt{elev\_10}, \texttt{elev\_50}, \texttt{area}) are topographic. Two attributes (\texttt{no\_gw\_perc} and 
\texttt{inter\_mod\_perc}) are hydrogeologic attributes. Details of these attributes 
can be found in Table 2 in \citet{CAMELS_GB} and references therein.

\section{Models trained on CAMELS}
In this section we present the results related to model selection and feature 
importance when training and predicting on CAMELS \citep{CAMELS_US}. This section 
is meant to show whether we are able to produce results similar to those of 
\citet{lstm_third_paper} in a way that is comparable to the rest of our experiments.
In addition, we present apparent feature importance of these trained models.
\subsection{Performance}
\begin{figure}
    \centering
    \includegraphics{{results_section/camels_us/cdf_val}.pdf}
    \caption[CDF plot of CAMELS models.]{Cumulative distribution function of the NSE score of models trained 
    on CAMELS \citep{CAMELS_US}. The LSTM models US$_\text{Kratzert}$ and US$_\text{None}$ 
    are described in Table \ref{all models} and are based on the models originally 
    trained by \citet{lstm_third_paper}. The SAC-SMA and VIC benchmarks are provided 
    by \citet{CAMELS_hydroshare}, NWM by \citet{NWMbench,lstm_third_paper}.} 
    \label{CAMELS-US CDF validation}
\end{figure}
Figure \ref{CAMELS-US CDF validation} shows the performance of our reimplementation 
of the  LSTM models created by \citet{lstm_third_paper} along with three traditional 
hydrological models. Table \ref{all models} contains more details on the LSTM models. 
"VIC" is the Variable Infiltration Capacity model 
calibrated on CAMELS. "SAC-SMA" is the SACramento Soil Moisture Accounting 
model calibrated on CAMELS. 
These benchmarks are provided by \citet{CAMELS_hydroshare} and are originally 
created by \citet{VICbench} and are trained per-basin as opposed to the other 
models.
"NWM" is a benchmark of the National Water Model run on CAMELS. 
This benchmark is available without any licensing at 
\citet{NWMbench} and we use an already preprocessed version provided by 
\citet{lstm_third_paper}.
The results here indicate that the process-driven models 
VIC and NWM perform similarly, SAC-SMA and US$_\text{none}$ perform 
similarly and better than the process-driven models and that there is a clear performance 
gap in favour of US$_\text{Kratzert}$. The LSTM models (US$_\text{Kratzert}$ and 
US$_\text{none}$) both perform with NSE values below zero for approximately five 
percent of the basins during cross validation.
\begin{figure}
    \centering
    \includegraphics{results_section/camels_us/prediction_best_kratzert.pdf}
    \caption[Highest scoring CAMELS prediction.]{Highest scoring prediction on the validation set  made using 
    US$_\text{Kratzert}$ compared to the observed outcome. "Obs" is observed runoff, 
    "Sim" is predicted runoff. The basin data is taken from CAMELS \citep{CAMELS_US}.}
    \label{best prediction kratzert}
\end{figure}

The highest scoring validation set prediction made using US$_\text{Kratzert}$ is 
shown in Figure \ref{best prediction kratzert}. It has an NSE score of $\approx 0.92$. 
As in the previous section we observe that the peak discharges are often either overestimated 
or underestimated.
\subsection{Importance}
\begin{table}
    \centering
    \caption[Ranking CAMELS attributes.]{Permutation importance of all static basin attributes used by 
    US$_\text{Kratzert}$ (same model configuration as in \citet{lstm_third_paper} 
    refit to the cross validation split used in this thesis), ranked by median 
    importance.}
    \input{{tables/results_section/kratzert_features_importance}.tex}
    \label{kratzert importance}
\end{table}
The permutation importances of the static basin attributes used by US$_\text{Kratzert}$ 
ranked by median importance are shown in Table \ref{kratzert importance}. Three 
out of the four top ranked attributes are also ranked in the top four by \cite{lstm_second_paper} 
using the same attribute subset but a different ranking method. 
\section{Models trained on CAMELS and CAMELS-GB}
In this section we present results related to model selection and feature importance 
when training and validating using both CAMELS and CAMELS-GB as a combined dataset.
This section is meant to show whether we can obtain satisfactory performance on 
ungauged basins from both datasets with the same model. 

\subsection{Performance}
\begin{figure}
    \centering
    \includegraphics{{results_section/mixed/cdf_val}.pdf}
    \caption[CDF plot of mixed models.]{Cumulative distribution function of the NSE score of LSTM models trained 
    on a dataset consisting of both CAMELS \citet{CAMELS_US} and CAMELS-GB \citep{CAMELS_GB}. 
    The models are described in Table \ref{all models}. The top figure shows the 
    performance of the models on CAMELS-GB and the bottom figure shows the performance 
    on CAMELS. The top figure is the cross validated performance on CAMELS-GB, the 
    bottom figure on CAMELS.}
    \label{mixed CDF validation}
\end{figure}
Figure \ref{mixed CDF validation} shows the cross validated performance of Mixed$_\text{lstm}$, Mixed$_\text{ea-lstm}$ and Mixed$_\text{none}$ trained on a dataset consisting of both CAMELS and CAMELS-GB. See Table \ref{all models} for information on these LSTM models.
On CAMELS-GB the models with basin attributes perform significantly better than 
the model trained without them. This also applies to the performance on CAMELS, 
but here the difference is smaller. The EA-LSTM and LSTM models with basin attributes 
perform similarly, having a median NSE of $~0.77$ on CAMELS-GB and $~0.65$ on CAMELS.
Compared to the best performing models in Figure \ref{CAMELS-GB CDF validation} and \ref{CAMELS-US CDF validation} 
the performance of the mixed model is comparable, although lower.
\begin{figure}
    \centering
    \includegraphics{{results_section/mixed/prediction_best_mixed_concat}.pdf}
    \caption[Highest scoring mixed prediction.]{Best predictions by Mixed$_\text{lstm}$ on CAMELS-GB (top) \citep{CAMELS_GB} 
    and CAMELS (bot) \citep{CAMELS_US} including catchment IDs and NSE.}
    \label{best prediction mixed concat}
\end{figure}

Figure \ref{best prediction mixed concat} shows the best predictions made by 
Mixed$_\text{lstm}$ on CAMELS-GB and CAMELS. The best performing basin by US$_\text{Kratzert}$ 
is the same as for Mixed$_\text{lstm}$. For CAMELS-GB we also include a prediction 
made on basin 50001 as that is the best performing basin for GB$_\text{lstm, all}$.
For CAMELS the best prediction of the combined model performs with an NSE 0.01 higher 
than that of the model trained on CAMELS. For CAMELS-GB it performs 0.02 lower.
\subsection{Importance}
\begin{table}
    \centering
    \caption[Common CAMELS and CAMELS-GB attributes ranked.]{Attribute importance ranked by median importance on CAMELS-GB \citep{CAMELS_GB} 
    as found using the permutation 
    test on Mixed$_\text{lstm}$. Each percentile column is split into two subcolumns, 
    one for CAMELS \citep{CAMELS_US} and one for CAMELS-GB. }
    \resizebox{\textwidth}{!}{%
        \input{{tables/results_section/mixed_concat_importance}.tex}}
    \label{importance mixed}
\end{table}
Table \ref{importance mixed} shows the attributes used by Mixed$_\text{lstm}$ 
ranked by median importance as found using the permutation test. Sorted by median 
importance on basins from CAMELS-GB. The highest median importance attribute on 
basins from CAMELS is \texttt{pet\_mean}, the highest on CAMELS-GB is \texttt{aridity}. 

\begin{figure}
    \centering
    \includegraphics{{results_section/runoff_ratio}.pdf}
    \caption{Rainfall-runoff ratio scatter plotted against NSE values per basin. 
    Pearson (P) and Spearman (S) correlation coefficients as well as their respective 
    p-values are shown in the figure.}
    \label{runoff ratio}
\end{figure}
As a summary of our importance analysis we include the performances of GB$_\text{lstm, all}$,
 US$_\text{Kratzert}$, SAC-SMA trained basin-wise, VIC trained basin-wise, NWM and 
 Mixed$_\text{lstm}$ plotted against \texttt{runoff-ratio} (An attribute not used 
 by any of the models. It is the full time series averaged ratio between precipitation 
 and runoff.) in an effort to analyze whether 
 our LSTM models interact differently with low rainfall-runoff ratio basins. 
Figure \ref{runoff ratio} shows that all models have Spearman correlations $\in (0.33,0.53)$ with 
 significant p-values. Only the traditional models show linear correlation, implying 
 a less direct relationship between the rainfall-runoff ratio and expected performance 
 for LSTM models.
\section{Models trained for transfer learning}
\label{Transfer learning section}
In this section we present results related to model selection and feature importance 
when training on CAMELS-GB and validating on CAMELS (GB$\rightarrow$US) and vice-versa. 
This section is meant to show whether we can use information in one dataset to be 
able to satisfyingly make predictions on the other.
\subsection{Performance}
\begin{figure}
    \centering
    \includegraphics{{results_section/transfer/cdf_val}.pdf}
    \caption[CDF of transfer models.]{Cumulative distribution function of the NSE score of LSTM models trained 
    on CAMELS \citep{CAMELS_US} and validated on a validation part of CAMELS as well as 
    the entirety of CAMELS-GB \citep{CAMELS_GB}. The top figure shows the 
    performance of the models on CAMELS-GB and the bottom figure shows the performance 
    on CAMELS.}
    \label{transfer CDF validation}
\end{figure}
\begin{figure}
\includegraphics{{results_section/transfer/training_progress}.pdf}
    \caption[Training progress Transfer$_\text{US, lstm, none}$]{Training performance per epoch of Transfer$_\text{US, none}$ and Transfer$_\text{GB, none}$ 
on CAMELS-GB (top) and CAMELS (bottom). The orange lines indicate the median NSEs, 
while the green lines indicate the mean NSEs.}
\label{training progress transfer}
\end{figure}
Figure \ref{transfer CDF validation} shows the cross validated performance of  
Transfer$_\text{US, ea-lstm}$, Transfer$_\text{US, lstm}$, Transfer$_\text{US, none}$, 
Transfer$_\text{GB, ea-lstm}$, Transfer$_\text{GB, lstm}$ and Transfer$_\text{GB, none}$ 
trained on CAMELS and validated on CAMELS-GB and vice-versa. 
For more information on the models, see Table \ref{all models}.
No models trained on CAMELS-GB perform at a satisfactory level 
on basins from CAMELS. The models trained on CAMELS all perform at a lower level 
on CAMELS-GB than models that are trained on CAMELS-GB. The best performing 
transfer model is Transfer$_\text{US, none}$, it has a median NSE of 0.52 on CAMELS-GB.
Compared to Transfer$_\text{GB, lstm}$, which has a median NSE of 0.77, this performance 
is significantly lower.  The transfer models also perform worse than expected on 
the dataset they are trained on as the chosen epoch is based on the performance 
on both datasets. This is illustrated in Figure \ref{training progress transfer}, 
which shows boxplots of the performance per epoch of Transfer$_\text{US, none}$ and Transfer$_\text{GB, none}$ 
per training epoch on both CAMELS-GB (top) and CAMELS (bottom). We observe that 
the performance of Transfer$_\text{US, none}$ increases on CAMELS-GB up until 
epoch 5 and then gradually decreases while it increases steadily and converges 
on CAMELS around epoch 14. The epoch optimized for both datasets which is shown in 
Figure \ref{transfer CDF validation} is epoch 9. For Transfer$_\text{GB, none}$ 
this is more apparent. Epoch 1 is the best epoch for the performance on CAMELS, 
while the performance on CAMELS-GB seems to increase for every epoch. The optimized 
epoch found for this model on both datasets is epoch 24.
\begin{figure}
\includegraphics{{results_section/transfer/predictions_best_train_us_no_static}.pdf}
    \caption[Highest scoring transfer learning predictions.]{Best predictions by Transfer$_\text{US, lstm, none}$ on CAMELS-GB (top) 
    \citep{CAMELS_GB} and CAMELS (bot) \citep{CAMELS_US} including catchment IDs and NSE.}
\label{predictions transfer}
\end{figure}

The best predictions made by Transfer$_\text{US, lstm, none}$ on CAMELS and CAMELS-GB 
are shown in Figure \ref{predictions transfer}. In addition predictions on basins 
50001 from CAMELS-GB and 14301000 from CAMELS are included in the figure to 
compare with the performance of GB$_\text{lstm, all}$ shown in Figure \ref{best prediction all concat seq len} 
and US$_\text{Kratzert}$ shown in Figure \ref{best prediction kratzert}. The model 
performs worse on CAMELS than US$_\text{Kratzert}$, worse on CAMELS and CAMELS-GB 
than Mixed$_\text{lstm}$ and worse on CAMELS-GB than GB$_\text{lstm, all}$.

As both cases (GB $\rightarrow$ US and US $\rightarrow$ GB)  show that the transfer 
learning works better without static attributes, we do not include an analysis 
of the importance in the transfer learning case.
\section{Test performance and summary.}
In this section we present test results from the models we choose from Section \ref{CAMELS-GB results}-\ref{Transfer learning section} 
in this chapter and compare with the cross validation performance. We use the test 
set performance to get an expected level of real world performance, in contrast to 
cross validation, which is used to compare models and optimize hyperparameters. 

\begin{comment}
\begin{figure}
\centering
\includegraphics{{results_section/camels_gb/cdf_test}.pdf}
    \caption{GB$_\text{lstm, all}$ refit on the full dataset and validated on the 
    test set compared with the cross validated performance on the train set.}
\label{test gb}
\end{figure}
\begin{figure}
    \centering
    \includegraphics{{results_section/camels_us/cdf_test}.pdf}
    \caption{US$_\text{Kratzert}$ refit on the full dataset and validated on the 
    test set compared with the cross validated performance on the train set.}
    \label{test us}
\end{figure}
\end{comment}
\begin{figure}
    \centering
    \includegraphics{{results_section/test/test_cdf}.pdf}
    \caption[Refit models testing performance.]{From the top: GB$_\text{lstm, all}$, US$_\text{Kratzert}$, Mixed$_\text{lstm}$ 
    and Transfer$_\text{US, lstm, none}$ refit on their respective full train datasets
    and validated on their test sets compared with the cross validated performance
    on their train sets.}
    \label{test cdf}
\end{figure}
The top plot in Figure \ref{test cdf} shows GB$_\text{lstm, all}$ refit on the full training set, 
trained for the optimal amount of epochs found via cross validation and validated 
on the test set. This is compared to the cross validated performance of the same 
model. We observe that cross validated and testing performance are similar.

Second from the top in Figure shows US$_\text{Kratzert}$ refit on the full training set 
compared to the cross validated performance. The performance is similar, although 
notably lower between the 40th and 70th percentile performant basins.

Third from the top we see the test set performance of Mixed$_\text{lstm}$ refit on 
the full training set and validated on the test set. The graphs overlap almost 
perfectly. 

The bottom plot is the test set performance of Transfer$_\text{US, lstm, none}$ 
refit on the full CAMELS training set. This is compared to the cross validated 
performance on CAMELS merged with the ensemble performance on CAMELS-GB. The 
graphs are similar in shape, although a notably higher amount of basin predictions 
have a negative NSE value.
\begin{table}
    \centering
    \caption{Summary table showing median validation and test NSE values of the 
    best models chosen from Section \ref{CAMELS-GB results}-\ref{Transfer learning section} 
    as well as the epoch optimized using cross validation.}
    \input{{tables/results_section/summary_results}.tex}
    \label{results summary table}
\end{table}
Finally, the validation and test performances as well as optimized epochs of the 
best models from Section \ref{CAMELS-GB results}-\ref{Transfer learning section}  are shown in Table \ref{results summary table}. For 
the models validated and tested on Both CAMELS and CAMELS-GB the median NSE values 
are shown separately. The optimized epochs are also shown. For more details on 
the models in question see Table \ref{all models}.
