In this chapter we discuss the implementation of the LSTM models described in Chapter 
\ref{lstm theory} and how the predictions of these models are used to try and gain 
insight into what physical processes our models deem the most important.
\section{Code available as Python package: CamelsML}
Originally a fork of the code in \citet{lstm_second_paper} with a few modifications, 
the machine learning code of this thesis is now implemented to be a fully fledged 
Python package. As the original code it is forked from, it is released under the 
Apache 2.0 license and anyone is therefore free to modify and implement the code 
into their own experiments in the future.
We dub this package CamelsML (Camels Machine Learning).


See Appendix \ref{camelsml documentation} for documentation on how to use the python 
package as well as a minimal running example.

\section{Preprocessing and combining datasets}
In statistical models it is important to have all inputs and outputs in unit-less 
form. A common way to achieve this is to normalize each input feature and outcome 
feature \citep{elemstatlearn}. 
We split the data basin-wise into train (75\%) and test (25\%) sets. 
Five-fold cross validation is used on the training set to evaluate model performance.
For each fold in the cross validation run, the data is normalized based on the current 
training set, excluding the chosen validation set in each cross validation iteration.
Mathematically this can be written as 
\begin{equation}
    \bm{a}_\text{norm} = \frac{\bm{a} - \bar{\bm{a}}_\text{train}}{\sigma_{\bm{a}_\text{train}}}. \label{normalization}
\end{equation}
Here $\bm{a}$ represents any variable, input or output. If $\bm{a}$ is a time series, 
the averaging is still done for all time steps in all basins in the training set, 
not individually per basin. This normalization is implemented in CamelsML by saving 
the standard deviations and averages of each feature in the training set to the disk 
and is implemented by us. \citet{lstm_third_paper} has likely also implemented this 
in a different way, but this code is not used here.

\begin{table}
    %\begin{adjustbox}{width=\textwidth}
    \centering
    \caption{Timeseries and attributes in Camels and Camels-GB that we treat as 
    equivalent. The names are taken directly from \citet{CAMELS_US} and \citet{CAMELS_GB}.}
    \input{tables/common_features_us_gb.tex}
    %\end{adjustbox}
    \label{attribute transfer}
\end{table}
When using a combination of CAMELS and CAMELS-GB we are limited in both which 
time series and which basin attributes we can use.
As seen in Chapter \ref{data} there are only two overlapping time series: precipitation 
and shortwave radiation. CAMELS-GB only has 
average daily temperature, while CAMELS has both minimum and maximum temperature 
per day. To include temperature as a feature we therefore make the assumption that 
\begin{equation}
    \bar{t}_\text{daily} \approx \frac{t_\text{min, daily} + t_\text{max, daily}}{2}. \label{average temp}
\end{equation}
The assumption in (\ref{average temp}) only holds when the daily temperature maxima 
and minima vary symmetrically around an equilibrium  \citationneeded.
Most of the basin attributes we include in the combined dataset have natural equivalents 
in both datasets, but there are two exceptions. We get an equivalent of the attribute 
forest\_frac in CAMELS in CAMELS-GB by assuming that
\begin{equation}
    \text{forest\_frac}_\text{GB} \approx \text{dwood\_frac} + \text{ewood\_frac} \label{forest gb}
\end{equation}
Our reasoning for (\ref{forest gb}) is that dwood\_frac and ewood\_frac are the only 
forest attributes in CAMELS-GB and it should therefore be safe to assume that adding 
these together yields the total percentage of wood cover.
For the CAMELS attribute gvf\_max we make a less safe assumption. \citet{CAMELS_US} 
describes this attribute as "maximum monthly mean of the green vegetation frac-tion". 
It could then follow that the percentage of land covers not categorized as urban 
or in water in CAMELS-GB can substitute this attribute. This yields
\begin{equation}
    \text{gvf\_max}_\text{GB} \approx 1 - \frac{\text{urban\_perc} + \text{inwater\_perc}}{100}. \label{gvf gb}
\end{equation}
We view the assumption (\ref{gvf gb}) to potentially be weak, and therefore exclude 
this attribute in one of our models.
A full overview of attributes deemed equivalent in CAMELS and CAMELS-GB is shown in 
Table \ref{attribute transfer}.

\begin{figure}
    \centering
    \includegraphics{feature_comparison_mixed/big_boxplot_mixed_validation.pdf}
    \caption{Boxplots of the basin attributes in CAMELS and CAMELS-GB compared. 
    CAMELS is on the left, CAMELS-GB is on the right. The subset of basins used 
    for this figure is taken from the validation basins in the first cross validation 
    iteration in model the mixed LSTM and EA-LSTM models trained on attribute subset d.}
    \label{attribute comparison}
\end{figure}

\section{Full training algorithm}
The training procedure described here is heavily based on and uses code from 
\cite{lstm_second_paper}.

More details on this is shown in the following 
algorithm:
\begin{figure}
\centering
\input{figures/tikz/mini_batch_training.tex}
\caption{A mini batch. $\bm{x}_{i,t}$ represents the input parameters $\bm{x}$ at time step $t$ for time series $i \in [0, b]$ where $b$ is the batch size. A mini batch consists of $b \times t$ FP32 numbers.}
\label{mini batch}
\end{figure}
The training algorithm can be described as:
\begin{enumerate}
    \item Split the training data basin-wise into five parts of equal size.
    \item Repeat the following five times, each time using a different 1/5 of the 
        split data as the validation set: \begin{enumerate}
            \item Initialize LSTM model with random weights and zero biases, except for the bias of the forget gate $\bm{b}_f$ which is initialized as $\bm{b}_f=\bm{5}$ to make the initial model either forget or remember idk \citationneeded
        \item Split each training time seres into several parts, the length 
            of which is decided by the sequence length variable $s$. A mini batch 
            consists of a batch size $s$ amount of these $s$ long time series. This 
                structure is shown in Figure \ref{mini batch}.
        \item For each mini batch:
        \begin{enumerate}
            \item Use the model to predict the outcomes of each time series in the 
                mini batch. This can be done in parallel.
            \item Use the average loss of all predictions in the mini batch to update 
                the model parameters using ADAM (see Section \ref{ADAM}).
        \end{enumerate}
        \item Evaluate on the validation set without updating parameters.
    \end{enumerate}
\end{enumerate}
We evaluate models using the Nashâ€“Sutcliffe model efficiency coefficient (NSE) \citep{NSE}.
This metric is similar to the $R^2$ score, but it is specialized for usage 
on hydrological time series.
It is defined as 
\begin{equation}
    \text{NSE} = 1 - \frac{\sum_{t=0}^T\left( y^t - \hat{y}^t\right)}{\sum_{t=0}^T\left(y^t - \bar{\hat{y}}\right)} \label{NSE}
\end{equation}
As we employ cross validation, we  end up with is 5 different models 
for each training run. These models do not necessarily converge to the same parameters 
as each other, making them potentially quite different from one another. To test the 
actual performance of a model (not just relative to other model configurations) we 
therefore need to train a new model with the same configuration (using the same features, 
hyperparameters, etc.) on the entire, undivided training set and test that model 
on the test set. This test result cannot be used to determine relative performance 
between different model configurations, but it can give an indication of the actual, 
real-world performance of a final selected model. Statistically, this is due to the 
fact that optimizing model configuration using the test set would mean overfitting 
on said test set. See \citet{elemstatlearn} for a more detailed explanation.

For models used to validate transfer learning between Camels and Camels-GB, we 
cross validate on one dataset and use all five models from the cross validation 
to make ensemble predictions on the validation split of the other dataset. This 
way we can get more robust statistics also in these results, as \citet{lstm_second_paper} 
showed that there often is a non trivial performance difference between a single
model and a model ensemble. In our case we assume this effect to be even higher 
because of the nature of training and validating on different datasets.

%\section{Model configuration}
%\begin{figure}
%\caption{Our full model configuration using an EA-LSTM \citep{lstm_second_paper}}.
%\end{figure}
\begin{table}
    \centering
    \caption{Table containing all models trained in this thesis along with their 
    given labels and configuration. All models are trained with a sequence length of 
    270 days and are initiated with the seed 19970204. 
    The attribute subsets a-e are shown in Table \ref{attribute table}
    The information contained here together with 
    CamelsML should be enough to easily be able to recreate the results in this thesis.
    The model configuration files are also located on the Github page of this thesis.}
    \input{tables/all_model_configs.tex}
    \label{all models}
\end{table}
\begin{landscape}
\begin{table}
    \centering
    \caption{Table containing all basin attribute dataset subsets. Set e is equal 
    to set d but without organic\_perc and gvf\_max.}
    \input{tables/attribute_selection.tex}
    \label{attribute table}
\end{table}
\end{landscape}

Table \ref{all models} shows all trained models from which results are presented in this 
thesis. The largest differences between these models are often which basin attributes 
are included in the training process. One should be able to reproduce the results 
of this work using this CamelsML, Table \ref{all models} and \ref{attribute table}. 
Doing exhaustive validation to decide which subset of attributes to use is not 
feasible with the amount of attributes present in the data of interest. What we instead 
do to end up with the subsets in Table \ref{attribute table} is a mix of a priori 
knowledge and validation: First we manually check which attributes to include based 
on perceived importance in accordance to known physical processes related to rainfall-runoff 
modelling. After training a model on a subset, we evaluate it using cross validation 
as mentioned earlier in this chapter. To give further context for the chosen subsets 
a-e we present this short summary:
\begin{itemize}
    \item a: This is a subset using all numerical static attributes in CAMELS-GB 
        \citep{CAMELS_GB} that are not derived from the outcome (runoff). 
    \item b: This is a smaller subset of the static attributes contained in CAMELS-GB. 
        This subset was created with emphasis on perceived importance with respect 
        to known physical processes. As many process-driven models (see Section \ref{VIC} and \ref{NWM}) have a high 
        emphasis on radiation (from vegetation), soil types and land cover we have 
        included all attributes related to soil, water content, vegetation and general land cover. 
        The geographical layout of a basin is also of interest and elevation attributes 
        are therefore included. The inclusion of the feature p\_mean (mean precipitation)
        is however not 
        physically motivated and merely stems from the fact that it was recognized 
        as one of the most important features in \citet{lstm_second_paper}'s analysis 
        using LSTMs on CAMELS \citep{CAMELS_US}. Mean precipitation should in 
        theory be information already given in the precipitation time series, but 
        our models do not have access to the entire precipitation time series while 
        training because of the limited sequence length. 
    \item c: This attribute selection is taken from \cite{lstm_third_paper} and 
        is used to reproduce the results of said paper with a different cross validation 
        setup to fit better with the rest of our analysis. \cite{lstm_third_paper} 
        used 12-fold cross validation while we use the more commonly employed 
        5-fold cross validation. 
    \item d: This is an attribute selection used for training models on both 
        CAMELS and CAMELS-GB at the same time in addition to transfer learning. 
        The attribute names stated in Table \ref{attribute table} are based on the 
        attribute names in CAMELS-GB. CAMELS and CAMELS-GB have different attributes 
        and different names for the same attributes. Which attributes we deem to 
        be equivalent are shown in Table \ref{attribute transfer}.
    \item e: The attributes organic\_perc and gvf\_max are excluded in this subset, 
        otherwise it is identical to subset e. We exclude these two features because 
        of uncertainty of whether our synthetic attribute creation works.
\end{itemize}

%\subsection{Feature selection}
\section{Using the permutation test to determine the model's perceived feature importance}
%\subsubsection{Permutation test}
\label{Feature selection}
One of the criticisms of machine learning methods
is that they are not easily interpretable. This 
is especially true if one wants to train a model 
on a dataset with an overwhelming amount of 
features. 
A way to interpret a machine learning model is to look at feature importance. There 
are many algorithms to determine feature importance, we choose to use the permutation 
test for its simplicity and ability to be used on any type of trained model.
Given a feature $j$, the permutation importance 
$i_j$ is equal to 
\begin{equation}
i_j = s - \frac{1}{K} \sum_{k=1}^K s_{k,j}\quad 
\label{Permutation equation}
\end{equation}
\citep{permutation} \citep{breiman2001random}.
Here $K$ denotes how many permutations we average over for each feature, $s$ is
the model's score on the original data and $s_{k,j}$ is the score of permutation 
number $k$ of the feature $j$. In essence (\ref{Permutation equation}) describes 
how much the performance of a model varies when "destroying" the information 
contained in a feature, therefore explaining the importance of the feature 
according to the current model. It is then important to remember that this is not 
the true importance of the feature, only the importance the model thinks the feature 
has. The scoring method $s$ can be any model scoring statistic, often the $R^2$
score for regression.
A major problem for this method is that (\ref{Permutation equation}) could give 
unrealistically low significance to features that are highly correlated to other 
features. In this case the feature may very well be important, but the information 
contained in it is also contained in one or more other correlated features, meaning 
the model doesn't lose as much information as one may think. Essentially the rule 
of thumb is that the feature importance is the feature's importance as learned by 
the model, not the actual importance in the real world. 
\section{Hardware}
The models are run on three different hardware configurations. The important difference 
between these hardware configurations is the amount of available VRAM. As LSTM models 
are recurrent neural networks they are not as parallelizable as other machine learning 
models (see (\ref{LSTM})). This means that the only way for us to fully exploit 
an increase in VRAM is to parallelize data-wise. To do this we increase the batch size.
The three hardware configurations are listed as follows \footnote{Note that we only 
state the used graphics card as this is the only important difference, we run no 
calculations on processors and do not use a significant amount of ordinary RAM.}:
\begin{enumerate}
    \item Nvidia GTX 980 ti: This has 6 GB of VRAM, we found a batch size of 1024 
        to be a sweet spot here.
    \item Nvidia GTX 1660 ti: Same as above.
    \item Nvidia Tesla V100 (Provided by Simula's eX3 cluster): This has 32 GB of VRAM, we find a batch size of 4096 
        to be a sweet spot. Anything more leads to a downgrade in speed because 
        of limitations in transferring data from the storage device to the GPU. 
        This is still not ideal and leads to an approximate 30\% utilization of the 
        GPU.
\end{enumerate}
We acknowledge that the inconsistent use of batch sizes across models may somewhat 
impact the model performance, as previously stated in Chapter \ref{stochastic gradient descent}.
However, as long as the amount of mini batches is sufficiently smaller than the number of data points we 
still get an acceptable amount of stochasticity in the training process and the batch 
size is usually set as high as possible in most machine learning practices because 
of model speed. Batch size is usually set as high as the hardware supports, as long 
as the total size of training data is $>>$VRAM \citationneeded.
Still, in an ideal situation we would use the same hardware for all training runs, 
but in this case we are limited by queue times on Simula's eX3 cluster in addition 
to the as of Q4 2020 $\rightarrow$ Q2 2021 silicon shortage making the acquisition of 
new graphics cards next to impossible \citep{GPUShortage}.
